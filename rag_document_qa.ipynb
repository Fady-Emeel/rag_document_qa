{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install everything needed for:\n",
        "# - embeddings (sentence-transformers)\n",
        "# - vector search (faiss)\n",
        "# - reading PDFs (pypdf)\n",
        "# - running local LLM (transformers)\n",
        "!pip -q install transformers sentence-transformers faiss-cpu pypdf pydantic accelerate bitsandbytes sentencepiece\n"
      ],
      "metadata": {
        "id": "Cwk6PU2YML3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core utilities\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n"
      ],
      "metadata": {
        "id": "RhgEQSqDMMOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a documents folder if it doesn't exist\n",
        "os.makedirs(\"documents\", exist_ok=True)\n",
        "\n",
        "# OPTIONAL but recommended:\n",
        "# Create sample policy docs so the RAG pipeline works even if you didn't upload anything yet.\n",
        "# You can replace these later with real PDFs/TXT.\n",
        "sample_docs = {\n",
        "    \"payments_policy.txt\": \"\"\"\n",
        "If a transfer fails but money is deducted, the customer must provide the transaction ID.\n",
        "Support will investigate within 24 hours and update the customer.\n",
        "If transaction ID is missing, request it before escalation.\n",
        "\"\"\",\n",
        "    \"refund_policy.txt\": \"\"\"\n",
        "Refunds are processed within 5 business days after verification.\n",
        "Duplicate charges require an order ID and payment reference.\n",
        "If the user was charged twice, create a refund ticket and attach the order ID.\n",
        "\"\"\",\n",
        "    \"security_policy.txt\": \"\"\"\n",
        "If an account is suspected to be hacked or fraud is reported:\n",
        "- Escalate to the security team immediately.\n",
        "- Mark the case as high priority.\n",
        "- Require human confirmation before any account action.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# Write sample docs only if documents folder is empty\n",
        "if len(os.listdir(\"documents\")) == 0:\n",
        "    for fname, content in sample_docs.items():\n",
        "        with open(os.path.join(\"documents\", fname), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(content.strip())\n",
        "    print(\"✅ Sample documents created in /documents\")\n",
        "else:\n",
        "    print(\"ℹ️ documents folder already has files:\", os.listdir(\"documents\"))\n"
      ],
      "metadata": {
        "id": "I238TrdlMNjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00cdc2f-1377-4dcb-e683-053fc9701467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ documents folder already has files: ['security_policy.txt', 'payments_policy.txt', 'refund_policy.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def load_documents(folder: str = \"documents\") -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Loads .txt and .pdf files from folder.\n",
        "    Returns:\n",
        "      texts: list of document/page text\n",
        "      sources: list of source identifiers (filename or filename#pageX)\n",
        "\n",
        "    IMPORTANT:\n",
        "    - PDF extract_text() sometimes returns None. We ignore empty/None pages.\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    sources = []\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        path = os.path.join(folder, file)\n",
        "\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read().strip()\n",
        "                if content:\n",
        "                    texts.append(content)\n",
        "                    sources.append(file)\n",
        "\n",
        "        elif file.lower().endswith(\".pdf\"):\n",
        "            reader = PdfReader(path)\n",
        "            for i, page in enumerate(reader.pages):\n",
        "                page_text = page.extract_text()\n",
        "                if page_text and page_text.strip():\n",
        "                    texts.append(page_text.strip())\n",
        "                    sources.append(f\"{file}#page{i+1}\")\n",
        "\n",
        "    return texts, sources\n",
        "\n",
        "documents, sources = load_documents(\"documents\")\n",
        "print(\"✅ Loaded docs/pages:\", len(documents))\n",
        "print(\"✅ Example source:\", sources[0] if sources else \"NO SOURCES\")\n"
      ],
      "metadata": {
        "id": "ZmEhUOW0MO5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7beeee-1826-4e81-841d-5d5243f9c23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded docs/pages: 3\n",
            "✅ Example source: security_policy.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text: str, chunk_size_words: int = 180, overlap_words: int = 40) -> List[str]:\n",
        "    \"\"\"\n",
        "    Why chunking:\n",
        "    - Vector search works better with smaller chunks.\n",
        "    - Overlap helps avoid losing context across boundaries.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(words):\n",
        "        end = start + chunk_size_words\n",
        "        chunk = \" \".join(words[start:end]).strip()\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "        start = end - overlap_words  # overlap\n",
        "        if start < 0:\n",
        "            start = 0\n",
        "    return chunks\n",
        "\n",
        "chunks = []\n",
        "chunk_sources = []\n",
        "\n",
        "for doc, src in zip(documents, sources):\n",
        "    doc_chunks = chunk_text(doc)\n",
        "    chunks.extend(doc_chunks)\n",
        "    chunk_sources.extend([src] * len(doc_chunks))\n",
        "\n",
        "print(\"✅ Total chunks:\", len(chunks))\n",
        "print(\"✅ Sample chunk:\\n\", chunks[0][:300] if chunks else \"NO CHUNKS\")\n",
        "\n",
        "# Guard: stop early if nothing loaded (common error)\n",
        "if len(chunks) == 0:\n",
        "    raise ValueError(\"No chunks created. Upload .txt/.pdf into /documents or check PDF extraction.\")\n"
      ],
      "metadata": {
        "id": "XH7VBfoRMQnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db2f7bb-72e1-4c5b-f377-74095042432f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total chunks: 3\n",
            "✅ Sample chunk:\n",
            " If an account is suspected to be hacked or fraud is reported: - Escalate to the security team immediately. - Mark the case as high priority. - Require human confirmation before any account action.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Embedding model: fast + good enough for portfolio RAG\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# normalize_embeddings improves similarity quality\n",
        "embeddings = embedder.encode(chunks, convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "print(\"✅ Embeddings shape:\", embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IcRPzImMSuC",
        "outputId": "0ec7c66c-d290-4207-fc5b-9643d37be11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings shape: (3, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "# FAISS stores vectors and searches nearest neighbors fast\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)  # IP (inner product) works well with normalized vectors\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"✅ FAISS index ready. Total vectors:\", index.ntotal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlY9khaBMVpY",
        "outputId": "04b93241-fa54-43ca-f98c-27511489bf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FAISS index ready. Total vectors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query: str, k: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Converts query to embedding, searches FAISS, returns top-k chunks with sources.\n",
        "    \"\"\"\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
        "    scores, idxs = index.search(q_emb, k)\n",
        "\n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], idxs[0]):\n",
        "        results.append({\n",
        "            \"text\": chunks[int(idx)],\n",
        "            \"source\": chunk_sources[int(idx)],\n",
        "            \"score\": float(score)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Quick retrieval test\n",
        "test_retrieval = retrieve(\"transfer failed money deducted\", k=3)\n",
        "test_retrieval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RDm--iLMXab",
        "outputId": "e85aa53e-b076-413e-c26c-d49289aa13e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'If a transfer fails but money is deducted, the customer must provide the transaction ID. Support will investigate within 24 hours and update the customer. If transaction ID is missing, request it before escalation.',\n",
              "  'source': 'payments_policy.txt',\n",
              "  'score': 0.6410048007965088},\n",
              " {'text': 'Refunds are processed within 5 business days after verification. Duplicate charges require an order ID and payment reference. If the user was charged twice, create a refund ticket and attach the order ID.',\n",
              "  'source': 'refund_policy.txt',\n",
              "  'score': 0.33896416425704956},\n",
              " {'text': 'If an account is suspected to be hacked or fraud is reported: - Escalate to the security team immediately. - Mark the case as high priority. - Require human confirmation before any account action.',\n",
              "  'source': 'security_policy.txt',\n",
              "  'score': 0.2704086899757385}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Instruction model that can follow \"ONLY use context\" style prompts\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    temperature=0.0,      # stable answers\n",
        "    do_sample=False,\n",
        "    max_new_tokens=300\n",
        ")\n",
        "\n",
        "print(\"✅ LLM loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAflg_kRMZGj",
        "outputId": "22c75fa2-1aaf-4e1b-ebac-a3a27c8e344e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rag_prompt(question: str, retrieved_chunks: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Key rule: model must answer ONLY from retrieved context.\n",
        "    If not found -> say \"Information not found...\"\n",
        "    \"\"\"\n",
        "    context = \"\\n\\n\".join(\n",
        "        [f\"[Source: {c['source']}] {c['text']}\" for c in retrieved_chunks]\n",
        "    )\n",
        "\n",
        "    return f\"\"\"\n",
        "You are a helpful assistant for enterprise support.\n",
        "\n",
        "You MUST answer using ONLY the Context below.\n",
        "- If the answer is not in the Context, reply exactly: \"Information not found in provided documents.\"\n",
        "- Do not invent policies.\n",
        "- Keep the answer short and actionable.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "rJZ2Qmd8Ma7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_answer(question: str, k: int = 3) -> Dict:\n",
        "    \"\"\"\n",
        "    Full RAG pipeline:\n",
        "    1) Retrieve top-k relevant chunks\n",
        "    2) Build prompt with context\n",
        "    3) Generate answer\n",
        "    4) Return answer + sources + a simple confidence score\n",
        "\n",
        "    Confidence here is heuristic:\n",
        "    - based on retrieval scores (not perfect but good for portfolio)\n",
        "    \"\"\"\n",
        "    retrieved = retrieve(question, k=k)\n",
        "\n",
        "    prompt = build_rag_prompt(question, retrieved)\n",
        "    out = llm(prompt)[0][\"generated_text\"]\n",
        "    answer = out.replace(prompt, \"\").strip()\n",
        "\n",
        "    # Simple confidence from top retrieval score (0..1-ish scale)\n",
        "    top_score = max([r[\"score\"] for r in retrieved]) if retrieved else 0.0\n",
        "    confidence = float(max(0.0, min(1.0, (top_score + 1) / 2)))  # rough scaling\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"sources\": list(dict.fromkeys([r[\"source\"] for r in retrieved])),  # unique, keep order\n",
        "        \"retrieval_scores\": [r[\"score\"] for r in retrieved],\n",
        "        \"confidence\": confidence\n",
        "    }\n"
      ],
      "metadata": {
        "id": "clpJZ1UoMdvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What should I do if my transfer failed but money was deducted?\",\n",
        "    \"How long do refunds take?\",\n",
        "    \"What should happen if fraud is reported?\",\n",
        "    \"Do you support Apple Pay?\"  # likely not in docs\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    resp = rag_answer(q, k=3)\n",
        "    print(json.dumps(resp, indent=2))\n",
        "    print(\"-\"*90)\n"
      ],
      "metadata": {
        "id": "Lo8-LIh2MgnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_SET = [\n",
        "    {\n",
        "        \"q\": \"What should I do if my transfer failed but money was deducted?\",\n",
        "        \"must_contain\": [\"transaction ID\", \"investigate\", \"24 hours\"]\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"How long do refunds take?\",\n",
        "        \"must_contain\": [\"5 business days\"]\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"What do you do when fraud is reported?\",\n",
        "        \"must_contain\": [\"security\", \"high priority\", \"human\"]\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"Do you support Apple Pay?\",\n",
        "        \"must_be_not_found\": True\n",
        "    }\n",
        "]\n",
        "\n",
        "def evaluate_rag(eval_set):\n",
        "    passed = 0\n",
        "    details = []\n",
        "\n",
        "    for item in eval_set:\n",
        "        resp = rag_answer(item[\"q\"], k=3)\n",
        "        ans_low = resp[\"answer\"].lower()\n",
        "\n",
        "        ok = True\n",
        "        if item.get(\"must_be_not_found\"):\n",
        "            ok = (\"information not found in provided documents\" in ans_low)\n",
        "        else:\n",
        "            for phrase in item[\"must_contain\"]:\n",
        "                if phrase.lower() not in ans_low:\n",
        "                    ok = False\n",
        "                    break\n",
        "\n",
        "        passed += int(ok)\n",
        "        details.append({\n",
        "            \"question\": item[\"q\"],\n",
        "            \"answer\": resp[\"answer\"],\n",
        "            \"sources\": resp[\"sources\"],\n",
        "            \"ok\": ok\n",
        "        })\n",
        "\n",
        "    report = {\n",
        "        \"tests\": len(eval_set),\n",
        "        \"passed\": passed,\n",
        "        \"pass_rate\": passed / len(eval_set)\n",
        "    }\n",
        "    return report, details\n",
        "\n",
        "report, details = evaluate_rag(EVAL_SET)\n",
        "print(report)\n",
        "for d in details:\n",
        "    print(\"\\nOK:\", d[\"ok\"])\n",
        "    print(\"Q:\", d[\"question\"])\n",
        "    print(\"Sources:\", d[\"sources\"])\n",
        "    print(\"A:\", d[\"answer\"])\n"
      ],
      "metadata": {
        "id": "yfaneyASMjQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rag_eval_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"report\": report, \"details\": details}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ Saved rag_eval_results.json (download it from Colab files)\")\n"
      ],
      "metadata": {
        "id": "qgiS0myHMla1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OluGW1_GMoFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}